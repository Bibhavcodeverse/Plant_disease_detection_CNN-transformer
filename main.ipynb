{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully!\n",
      "🔹 Final Prediction: Grape___Black_rot\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define CNN Feature Extractor\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        base_model = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)  # (batch, 2048, H, W)\n",
    "\n",
    "# Define Transformer Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, dim=2048, heads=8, ff_dim=2048, dropout=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=dim, num_heads=heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_out)\n",
    "        return x\n",
    "\n",
    "# Define Full CNN + Transformer Model\n",
    "class CNN_Transformer_Model(nn.Module):\n",
    "    def __init__(self, num_classes=38):\n",
    "        super(CNN_Transformer_Model, self).__init__()\n",
    "        self.cnn = CNNFeatureExtractor()\n",
    "        self.transformer = TransformerEncoderBlock(dim=2048)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)  # Shape: (batch, 2048, H, W)\n",
    "        x = x.flatten(2).permute(2, 0, 1)  # Reshape to (seq_len, batch, 2048)\n",
    "        x = self.transformer(x)  # Transformer processes this shape\n",
    "        x = x.mean(dim=0)  # Global Average Pooling\n",
    "        x = self.fc(x)  # Final classification layer\n",
    "        return x\n",
    "\n",
    "# Load Model\n",
    "model_path = \"C:/Users/BIBHAV KUMAR/Desktop/COMPLETE_HYBRID_MODEL_PLANTDISESASE/model/cnn_transformer_model.pth\"\n",
    "num_classes = 38  # Set this based on your dataset\n",
    "model = CNN_Transformer_Model(num_classes)\n",
    "\n",
    "# Load state dict and fix DataParallel keys if needed\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    new_state_dict[k.replace(\"module.\", \"\")] = v\n",
    "model.load_state_dict(new_state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(\"✅ Model loaded successfully!\")\n",
    "\n",
    "# Image Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Prediction Function\n",
    "def predict_image(image_path, model, class_names):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    predicted_class_idx = torch.argmax(probabilities, dim=1).item()\n",
    "    return class_names[predicted_class_idx]\n",
    "\n",
    "# Define Class Names\n",
    "class_names = [ \"Apple___Apple_scab\",\n",
    "    \"Apple___Black_rot\",\n",
    "    \"Apple___Cedar_apple_rust\",\n",
    "    \"Apple___healthy\",\n",
    "    \"Blueberry___healthy\",\n",
    "    \"Cherry___healthy\",\n",
    "    \"Cherry___Powdery_mildew\",\n",
    "    \"Corn___Cercospora_leaf_spot Gray_leaf_spot\",\n",
    "    \"Corn___Common_rust\",\n",
    "    \"Corn___healthy\",\n",
    "    \"Corn___Northern_Leaf_Blight\",\n",
    "    \"Grape___Black_rot\",\n",
    "    \"Grape___Esca_(Black_Measles)\",\n",
    "    \"Grape___healthy\",\n",
    "    \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
    "    \"Orange___Haunglongbing_(Citrus_greening)\",\n",
    "    \"Peach___Bacterial_spot\",\n",
    "    \"Peach___healthy\",\n",
    "    \"Pepper,_bell___Bacterial_spot\",\n",
    "    \"Pepper,_bell___healthy\",\n",
    "    \"Potato___Early_blight\",\n",
    "    \"Potato___healthy\",\n",
    "    \"Potato___Late_blight\",\n",
    "    \"Raspberry___healthy\",\n",
    "    \"Soybean___healthy\",\n",
    "    \"Squash___Powdery_mildew\",\n",
    "    \"Strawberry___healthy\",\n",
    "    \"Strawberry___Leaf_scorch\",\n",
    "    \"Tomato___Bacterial_spot\",\n",
    "    \"Tomato___Early_blight\",\n",
    "    \"Tomato___healthy\",\n",
    "    \"Tomato___Late_blight\",\n",
    "    \"Tomato___Leaf_Mold\",\n",
    "    \"Tomato___Septoria_leaf_spot\",\n",
    "    \"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "    \"Tomato___Target_Spot\",\n",
    "    \"Tomato___Tomato_mosaic_virus\",\n",
    "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\"]\n",
    "\n",
    "# Example Prediction\n",
    "image_path = \"img2.JPG\"\n",
    "predicted_class = predict_image(image_path, model, class_names)\n",
    "print(f\"🔹 Final Prediction: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIBHAV KUMAR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BIBHAV KUMAR\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define CNN Feature Extractor\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        base_model = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)\n",
    "\n",
    "# Define Transformer Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, dim=2048, heads=8, ff_dim=2048, dropout=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=dim, num_heads=heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_out)\n",
    "        return x\n",
    "\n",
    "# Define CNN + Transformer Model\n",
    "class CNN_Transformer_Model(nn.Module):\n",
    "    def __init__(self, num_classes=38):\n",
    "        super(CNN_Transformer_Model, self).__init__()\n",
    "        self.cnn = CNNFeatureExtractor()\n",
    "        self.transformer = TransformerEncoderBlock(dim=2048)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.flatten(2).permute(2, 0, 1)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=0)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Load Model\n",
    "model_path = \"C:/Users/BIBHAV KUMAR/Desktop/COMPLETE_HYBRID_MODEL_PLANTDISESASE/model/cnn_transformer_model.pth\"\n",
    "num_classes = 38\n",
    "model = CNN_Transformer_Model(num_classes)\n",
    "\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    new_state_dict[k.replace(\"module.\", \"\")] = v\n",
    "model.load_state_dict(new_state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "# Define Class Names\n",
    "class_names = [\n",
    "    \"Apple___Apple_scab\", \"Apple___Black_rot\", \"Apple___Cedar_apple_rust\", \"Apple___healthy\",\n",
    "    \"Blueberry___healthy\", \"Cherry___healthy\", \"Cherry___Powdery_mildew\",\n",
    "    \"Corn___Cercospora_leaf_spot Gray_leaf_spot\", \"Corn___Common_rust\", \"Corn___healthy\", \"Corn___Northern_Leaf_Blight\",\n",
    "    \"Grape___Black_rot\", \"Grape___Esca_(Black_Measles)\", \"Grape___healthy\", \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
    "    \"Orange___Haunglongbing_(Citrus_greening)\", \"Peach___Bacterial_spot\", \"Peach___healthy\",\n",
    "    \"Pepper,_bell___Bacterial_spot\", \"Pepper,_bell___healthy\", \"Potato___Early_blight\", \"Potato___healthy\",\n",
    "    \"Potato___Late_blight\", \"Raspberry___healthy\", \"Soybean___healthy\", \"Squash___Powdery_mildew\",\n",
    "    \"Strawberry___healthy\", \"Strawberry___Leaf_scorch\", \"Tomato___Bacterial_spot\", \"Tomato___Early_blight\",\n",
    "    \"Tomato___healthy\", \"Tomato___Late_blight\", \"Tomato___Leaf_Mold\", \"Tomato___Septoria_leaf_spot\",\n",
    "    \"Tomato___Spider_mites Two-spotted_spider_mite\", \"Tomato___Target_Spot\", \"Tomato___Tomato_mosaic_virus\",\n",
    "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\"\n",
    "]\n",
    "\n",
    "# Image Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Prediction Function\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    predicted_class_idx = torch.argmax(probabilities, dim=1).item()\n",
    "    return class_names[predicted_class_idx]\n",
    "\n",
    "# Tkinter GUI\n",
    "class DiseaseDetectionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Plant Disease Detection\")\n",
    "        self.root.geometry(\"600x500\")\n",
    "\n",
    "        self.label = tk.Label(root, text=\"🌱 Plant Disease Detection\", font=(\"Arial\", 16, \"bold\"))\n",
    "        self.label.pack(pady=10)\n",
    "\n",
    "        self.upload_button = tk.Button(root, text=\"📂 Upload Image\", command=self.upload_image, font=(\"Arial\", 12))\n",
    "        self.upload_button.pack()\n",
    "\n",
    "        self.canvas = tk.Canvas(root, width=300, height=300)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.result_label = tk.Label(root, text=\"\", font=(\"Arial\", 14, \"bold\"), fg=\"green\")\n",
    "        self.result_label.pack()\n",
    "\n",
    "        self.predict_button = tk.Button(root, text=\"🔍 Predict\", command=self.predict_disease, state=tk.DISABLED, font=(\"Arial\", 12))\n",
    "        self.predict_button.pack(pady=10)\n",
    "\n",
    "        self.image_path = None\n",
    "\n",
    "    def upload_image(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        if file_path:\n",
    "            self.image_path = file_path\n",
    "            image = Image.open(file_path)\n",
    "            image = image.resize((300, 300))\n",
    "            self.photo = ImageTk.PhotoImage(image)\n",
    "            self.canvas.create_image(150, 150, image=self.photo)\n",
    "            self.predict_button.config(state=tk.NORMAL)\n",
    "\n",
    "    def predict_disease(self):\n",
    "        if self.image_path:\n",
    "            predicted_class = predict_image(self.image_path)\n",
    "            self.result_label.config(text=f\"🌿 Prediction: {predicted_class}\")\n",
    "\n",
    "# Run Tkinter App\n",
    "root = tk.Tk()\n",
    "app = DiseaseDetectionApp(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
